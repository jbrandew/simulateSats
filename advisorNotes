Continuous notes from advisor meetings:  

Meeting 1/4/23: 
what are we doing? preparing for meeting. 
what are we updating on? current progress and future steps. 

Done so far: 
majority of the paper (topologies, simulating results of like mean connection time) 
expandible topologies (3 ISL spiral topology -> 2-3 or others) 
easy to add base stations
easier graphical analysis 
used structure in analyzing proximity of satellite to usage 

Next steps: 
Implement dynamic routing paper and compare results 
Self teach and implement RL algorithm baselines 
Implement RL algorithms with just pLEO case 
Expand into multi level satellites (so diff kinds of players), more stochastic elements (higher state space), randomized state, and then possibly continuous time frame analysis (continuous time would allow me to 

Orbital altitude regime -> if im at 750 KM...
	-can adjust data rate with range (to account for atteuatian) 
	-attenuation for hitting atmosphere (100 km is fine of atmospheric effects) 

highier field of view in geo
maybe better hardware geo, (austere env.) -> tougher radiation environment in GEO
-higher service life GEO
-comparable processing power at GEO 

GEO could be a producer and ---- of data, not just relay
high rate leo data transport layers -> other layers are feeding data into it

GEO might be able to widely transmit to other satellites...

Questions: 
How do i compare this to a purely terrestrial setup in terms of performance?
-fiber doesnt go everywhere, satellite with optical connections is nice
-compare to greedy case of connecting to nearest satellite vs optimized algorithm  
Should i be constraining computational complexity at all in terms of on board hardware for satellites? 
-can assume unconstrained 
-
Should there be communication limitations for scheduling/sending messages i should be aware of? 
How long did a simulation take for you to run with avg transmit time for 1000 trials? 
Should i be implementing some of this in cpp in end goal for RL? I can mix cpp for computationally hard algorithms, and then use python for the overhead project structure etc. 
-

More context: 
alleria -> spin off from google for satcom...(space time tool) 
aalyria
-DOD has some contracts with them 
might be able to get some copy of space time tool 
developers interface...could maybe improve a component of the tool, like topology manager 
(they are contracting with alot of people across globe....?) 

northbound southbound interface...maybe east and west between diff segments 

SDA constellation info -> standards for some inter satellite links 
-can use reference for simulation components 
https://www.sda.mil/wp-content/uploads/2020/08/9100-0001-01-OISL-Standard.pdf
https://www.sda.mil/wp-content/uploads/2022/04/SDA-OCT-Standard-v3.0.pdf

optical vs RF 
-optical specific area but high data rate -> 
-RF -> large area with one phased array antenna (many connections, lower data rate) 

Implement;
distributed case with communication 
link discovery packets...advertise distances 
BF with ISL connections (distributed ISL connections, # of hops away) 
alyria assumes centralized....

SDN uses centralized... 

more interesting: what is the actual algo for getting routes/topology
-not necessary to compare latency of centralized vs non centralized
-woulda maybe be cool to have kind of distributed with a # of base stations.... 

look at alyria stuff! 

Meeting 1/18/23: 
what are we doing? preparing for meeting. 
what are we updating on? current progress and future steps. 

I'm sorry, I got pretty distracted these past two weeks working on a different algorithm, as Dr. Brinton knows. It was possibly applicable to this project though, and it worked with minimizing the # of a certain size clique.

Also, responding to the action items from last week, here are some concerns I had: (refernce them). 

greedy edge assignment: 
-could be useful for best edge allocation for max degree of graph 
-could constrain for max out degree of a satellite 

graph theory course materials 

other notes/prep stuff for this meeting: 

action items: 

follow these action items. (simulation, routing, topology, then ways for potential routing) 
-routing or topology, RL is a good approach
-links you can form and user demands -> stimuli for RL algo. 

could spread out users -> each need 10b/s, evaluate how well they satisfy stuff 
-should be nonuniform or uniform traffic demand
-could be uniform and then sudden hotspot -> how does the system respond/change its connectivity 

-priority/size/requried BW of packets...maybe...not really mut. ex. 
-modeling overhead of switching ISLs -> one of the standards has reconnection time for satelliets (paramaterize over) 
	-compare answers of toplogy for different reconnection times 
	

a. modify simulation enviroment to include: 
-attenuation effects of ISLs that cross the 100km threshold in atmosphere 
-put a cost to adding an ISL. Might make higher orbit GEOs more worth it, as they require less connections, as their field of view is wider 
-impelement facets from SDA standards, which include: 
https://www.sda.mil/wp-content/uploads/2020/08/9100-0001-01-OISL-Standard.pdf
https://www.sda.mil/wp-content/uploads/2022/04/SDA-OCT-Standard-v3.0.pdf

b. run throughput caluclations and compare: 
-greedy case of connecting to nearest satellite (s) in the various topologies vs the case of using our algorithm that we develop 

c. look into research with the alyria tool for topology management 

d. compare output of using optical connections vs RF connections 
-optical: specific area, high data rate 
-RF: large area, low data rate (phased array antenna) 

e. implement the distributed case of communication
-so, each satellite doesnt know the whole topology (what connections each other one makes, etc.)
-"link discovery packets" are used, advertising distances/connections 
-this could be better than Alyria, which assumes centralized.

f. exploring this notion of maximaly spread out choice of edges/links 

Questions: 
on e, the general process is:  

init: 
-each sat is connected to n nearest satellites 

repeat step: 
-advertise what satellites you are connected to to the satellites you are connected to and distances to nearby satellites 
-based on a policy and what nearby satellites say to you, change who you are connected to next 


questions: 
-each satellite is changing who they are connected to based on information from other satellites, which in the next time step may be false (as satellites may have changed their connections)
-BF algorithm worked with finding shortest path between one node and all other nodes via a distributed manner, but that was in a static graph (ISLs didnt change, nor did distances between satellites). So it doesnt seem super applicable to this situation 
	-like, the "reliability/accuracy" of channel/topology state information is dependent on 	
	how far satellites are from each other 
	
	-fish eye routing: (less frequent link updates on others away) 
	-geographic routing/groupign those in a certain area 
	-toplogy construction vs routing problem (which one im trying to solve) 
	-"geneated algorithm.." with toplogy construction
	-notion of "age of information".... (considered with RL, why its good) 
	-RL could pick up on more complex relationships 
	
-what if there is some general information known by each satellite?
	-for example, it seems plausible that in a walker delta constellation, every satellite 
	would easily know where every other satellite is. however, the packet processing delay/
	how many packets are already queued up could be seen as a stochastic process
	
	-probably reliable to assume we know yea...notice failures 
	 
-are there algorithms for shortest path in a changing graph? 
-should there be a notion of "recomputing" only when the adjacency matrix we computed when establishing our last policy differs by a certain threshold from the current state/adj matrix? 


how do me measure throughput/performance of a certain policy/compared to baseline? 
-in a static case without moving, evaluate the average latency of a packet (so between a pair of nodes). 
-repeat that many times.... 

-if im constrainted on uplink or crosslink capacity -> how does that change components/policy 

More questions: 
-essentially all the topologies involve only ISLs for satellites that are moving in relatively the same direction (no northbound-southbound
connections are used). Is there any reason for this? (other than minimizing the # of changes in topology)
-why are IPO ISLs allowed to violate the polar region constraint, but inter plane ISLs are not allowed to? 
-for ISLs that move in and out of violating constraints like polar region or sun exclusion angle, how should we approach the reconnction method?
are they just "not used" while violating the constraint, or are they fully disconnected and then reconnected? 
-are polar links allowed if they are to a base station? 

Notes:
-this means that the general policy/average use case is the same between time varying and not, as the ISLs always remain the same regardless of moving in time. well, its an average over distance between satellites in the same plane/2

gnu radio: complexity level too intense -> abstract it 

packet level: TCP routing 
-(ARQ etc.) 
-specific policies for diff environemnts. 

given topology -> determine
stress test loading with different topologies 
-&response to stress/breaking
-traffic loading scenarios
	-specific distribution for traffic demands based 	on population densities 
	-each person -> specific BW requested (maybe 	stochastically gen.) 

-get into traffic bottlenecks from routing 
-even possibly get into static traffic loading (with omniscient knowing) -> saturation location 

BER, function of:
-distance
-interference from other users that have proximally close paths
	-optical links at sats->low interference 
	-RF interference. from uplink 
-

capacity of given link -> allows abstraction of packet 
level comms 


Adapting rate to the SNR...longer links -> smaller available data rate/BW efficiency 
-link models
-SDA : optical modes for some links 
-link budgets for sats
-starlink user terminal gain/directionality/link budgets

physical limitations of directional connections
(not necessarily ruled out) 
dense cluster at polar -> connections are more difficult at polar level for between planes (harder coordination)
lower length of connection -> less value in a hop 
reestablish -> still have that overhead 
polar links for gateway are allowed -> less overhead 
(ground station # is limited, valuable #) 

ring of ISLs with normal towards the sun are affected by exclu. 

change housing 
-check which university the housing is at (check if theres AC) 

Thought process: 
in dealing with link budgets, we have the following model: 

What did Dr. Wolf say? 
-abstract it to the link budget model. 
-so, we have a specified power constraint. then, based on min SNR functionality and parameters such as 
antenna type and maybe other user interference, characterize each link by: 
	-an equation with min power and corresponding capacity, as well as equation for capacity at each level of power allocation 
	-this will use the normal link budget equation
-then, each satellite has: 
	-a set of characterized possible links based on global constellation knowledge (this doesnt go into inter satellite interference) 
	-a given power they can divide among some chosen set of links 

concerns: 
-this doesnt go into any joint behavior. ex. what to do if a satellite tries to make a connection with another satellite but that other 
satellite already has a max # of connections 
-needed discrimination among chosen satellites for "singular diversity"...( stochasticness may be nice here for a policy i develop specifically,
if im looking outside the realm of RL) 

so, next steps: 
implement link budget model
-specifically optical link budgets (look into multiuser interference for optical connections)
implement greedy (maxing output capacity, verify its the same as nearest) 
simulate net throughput/average latency with single packet case (averaging over time frames) 
	-not sure how to get into simulating traffic/possible overhaul 
	-maybe, since the relative time of satellites traveling vs the path of a packet is very different, we could look at 
	monte carlo set of constellation states, and then for each of those constellations, look at traffic properties  
simulating SNR for link budget model optimization with other user interference may require wider topology/state information

notes:
-prioritizing fairness vs throughput -> different loss models/prioritization in policy for RL 

time sequencing -> each satellite has a set of links 

more specific next steps: 
-find content for link budgets for optical connections
-look into multiuser interference for optical connections 
	-apparently you dont see much with it 
-create class for ISL that characterizes:
	-getting current min power for connection 
	-given power, what capacity can you provide 
	-...maybe some metric of "stability" over time 
-look into the type of theory for creating network based on these....

Questions: 
-which model would you prefer i use? 
https://www.mathworks.com/help/satcom/ug/optical_satellite_communication_link_budget_analysis.html
https://arxiv.org/pdf/2204.13177.pdf
or something else?
-in the capacity formula, there is the notion of what bandwidth we use for the connection. If users in optical communications
do not face inter user interference, then what is the actual bandwidth thats used? cause, if there is no interference, why couldnt we use 
the whole spectrum? 
	-optical -> limited more from hardware constraints (can use any bandwidth) 
	-the "shot" thing with low enough SNR -> not sampling enough photons
	-power limited on optical links vs BW links 
-with capacity and arbitrary low error, why do we have the parameter of "link margin" 
	-It gives us the receive power, which is used in capacity 
	-asking for link budget model 
-is there a good algorithm in which to solve the problem outlined below? 
say i have a graph with a set of weighted edges
then, say that each node has a constrained degree/# of edges it has 
then, say i want to choose a subset of weights in which the average path length between nodes is minimized. 
	-minmimizing diameter -> what to do (diameter is actually just weight of 1) 

-is the event structure/way im using to reconcile multiple time dependent processes ok? 
	

what i was trying to do: 
-have real time dependency for simulated results. as in, 1 second passes in real world may incur 2 minutes in simulation, or something similar. would require. the problem with this is it accounting for stuff like computation time, it would be very hard to synchronize the many processes that involve: packet location, status of servers, location of satellites, etc. 

what i think im going to do: 
-each user processes time a different way, and then each has a type of event depending on time resolution of time frame procedure, and we have an "event processor." The accuracy of results may then heavily depend on the resolution of time. Examples: 
-if i have two packets traveling over the air, and each has a travel time of 1 and 2 secs respectively. If i have a time frame length of 3 secs, then at the next time frame, both packets arrive at the server at the same time. 
-if i have 10 packets waiting to be processed at the server, and the server has a exp. interdeparture time, then for the certain time frame, i can simulate how many packets are processed within that time frame, which will be an accurate method based on memoryless system... 

-do users that are on the earth use the nearest satellite, or the satellite associated with the shortest path? 
-if i have a certain power for outgoing edge, and certain power for ingoing edge allocated for each, should this be more of a directed
graph optimization then? 

each user has a time event with a specific time stamp -> process it in the event queue 	
-chain of events (metrics collected, etc.) 
-could discretize/assign resolution of some processes
-so just stack of events 


Okay, so we have the problem of: 
-each link has a set of bandwidth efficiencies, based on discretized parts of receive power 
-we have n*n possible links, where n = number of satellites. this is not limited by LOS, etc. 
-we need to choose a subset of which that gives us the shortest average path length, and enact a policy to do so 

okay, said algoritm doesnt exist it seems like


thoughts: 
does the sub problem solution contribute to the optimal larger solution? 
how do we simplify this? -> remove constraints for now. 


given n edges we can pick, what method minimizes the inter node path length? (without the previous constraints)

bidirectional links (distance is really the only thing discriminating between links) 

could examine flow vs packet level for capacity evaluation 
-age of information 
-could also make when packets are sent out stochastic as well 

RL: could maximize own stuff greedily, but then also have a penalization term for affecting others in the network
-aggregating local policies at a head honcho
-could have different local models depending on the constellation/location 
-could have "group level personalization" for different satellite models 

the idea of "flow splitting" depending on packet size....

[5]	X. Wang, Z. Dai, and Z. Xu, “Leo satellite network routing algorithm based on reinforcement learning,” 2021 IEEE 4th International Conference on Electronics Technology (ICET), 2021. doi:10.1109/icet51757.2021.9451072

and look at others


























